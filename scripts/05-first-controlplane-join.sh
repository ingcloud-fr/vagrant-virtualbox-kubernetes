#!/bin/bash
set -e

# ======================================
# 05 - N≈ìud multi/controlplane Kubernetes 
# ======================================

# Ce script initialise le cluster Kubernetes
# Il s'ex√©cute uniquement sur le controlplane

# Variables
K8S_VERSION="1.32"
CNI_PLUGIN=${CNI_PLUGIN:-cilium}
POD_CIDR="10.244.0.0/16"
CLUSTER_NAME=${CLUSTER_NAME:-k8s}
CONTROLPLANE_VIP="${CONTROLPLANE_VIP:-192.168.1.210}"
NUM_CONTROLPLANE="${NUM_CONTROLPLANE:-1}"
IP_START="${IP_START:-192.168.1.200}"
BASE_IP=$(echo "$IP_START" | cut -d. -f1-3)
START_OCTET=$(echo "$IP_START" | cut -d. -f4)

echo "‚öôÔ∏è  Installating the first controlplane ..."

# R√©cup√©ration de l'IP locale (export√©e dans 01)
MY_IP=$(grep PRIMARY_IP /etc/environment | cut -d= -f2)

# G√©n√©ration du fichier /vagrant/hosts 
cat <<EOF > /vagrant/hosts
# Hosts list generated by Vagrant
127.0.0.1 localhost
# The following lines are desirable for IPv6 capable hosts
::1	ip6-localhost	ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
ff02::3	ip6-allhosts
EOF

# # Add haproxy-vip in /vagrant/hosts
# if [ "$NUM_CONTROLPLANE" -gt 1 ]; then
#   echo "$CONTROLPLANE_VIP $CLUSTER_NAME-haproxy-vip" >> /vagrant/hosts
# fi

# Ajout de l'IP locale
echo "$MY_IP $(hostname)" >> /vagrant/hosts

# If there are several controlplanes, the API endpoint is the VIP else it MY_IP
if [ "$NUM_CONTROLPLANE" -gt 1 ]; then
  ADVERTISE_IP=$CONTROLPLANE_VIP
else
  ADVERTISE_IP=$MY_IP
fi

# INIT
echo "‚öôÔ∏è  Pull images for kudeadm ..."
kubeadm config images pull
echo "‚öôÔ∏è  Cluster initialization with kubeadm init --control-plane-endpoint $ADVERTISE_IP:6443 ... "
kubeadm init --control-plane-endpoint $ADVERTISE_IP:6443 \
  --upload-certs \
  --apiserver-advertise-address $MY_IP \
  --pod-network-cidr=$POD_CIDR

# R√©cup√©ration du hash et token join
JOIN_COMMAND_CONTROLPLANE=$(kubeadm token create --print-join-command)
HASH=$(echo "$JOIN_COMMAND_CONTROLPLANE" | grep -o 'sha256:[a-f0-9]*')
TOKEN=$(echo "$JOIN_COMMAND_CONTROLPLANE" | awk '{print $5}')

# R√©cup√©ration de la cl√© pour le join en mode control-plane
CERT_KEY=$(kubeadm init phase upload-certs --upload-certs | tail -1)

if [ "$NUM_CONTROLPLANE" -gt 1 ]; then
  # G√©n√©ration du script de join pour les autres controlplanes
  JOIN_CONTROLPLANE="kubeadm join ${CONTROLPLANE_VIP}:6443 --control-plane --token ${TOKEN} --discovery-token-ca-cert-hash ${HASH} --certificate-key ${CERT_KEY}"
  echo "$JOIN_CONTROLPLANE" > /vagrant/join-controlplane-${CLUSTER_NAME}.sh
  cat <<EOF > /vagrant/join-controlplane-${CLUSTER_NAME}.sh
#!/bin/bash
$JOIN_CONTROLPLANE "\$@"
EOF
  chmod +x /vagrant/join-controlplane-${CLUSTER_NAME}.sh
  chown vagrant:vagrant /vagrant/join-controlplane-${CLUSTER_NAME}.sh
fi
# NOTE : the ending "\$@" allow secondary controlplan to pass argument when invoking the script (as --apiserver-advertise-address=xxx)

# G√©n√©ration du script de join pour les workers 
JOIN_WORKER="kubeadm join ${ADVERTISE_IP}:6443 --token ${TOKEN} --discovery-token-ca-cert-hash ${HASH}"
echo "$JOIN_WORKER" > /vagrant/join-${CLUSTER_NAME}.sh
cat <<EOF > /vagrant/join-${CLUSTER_NAME}.sh
#!/bin/bash
$JOIN_WORKER "\$@"
EOF
chmod +x /vagrant/join-${CLUSTER_NAME}.sh
chown vagrant:vagrant /vagrant/join-${CLUSTER_NAME}.sh

# Configuration de kubectl pour le user vagrant
mkdir -p /home/vagrant/.kube
cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
chmod 600 /home/vagrant/.kube/config
chown -R vagrant:vagrant /home/vagrant/.kube

# Copie du kubeconfig pour les autres nodes
cp /etc/kubernetes/admin.conf /vagrant/admin.conf
chown vagrant:vagrant /vagrant/admin.conf

# Cr√©ation de cl√©s pour SSH ET SCP entre nodes
# Recopi√© sur tout les nodes √† la fin
# echo "‚öôÔ∏è  Cr√©ation de cl√©s ssh sur le controlplane"
# ssh-keygen -t rsa -b 2048 -N "" -f /root/.ssh/id_rsa
# chown vagrant:vagrant /root/.ssh/id_rsa
# chmod 600 /root/.ssh/id_rsa
# cp /root/.ssh/id_rsa.pub /vagrant/id_rsa.root.${CLUSTER_NAME}.pub

# ssh-keygen -t rsa -b 2048 -N "" -f /home/vagrant/.ssh/id_rsa
# chown vagrant:vagrant /home/vagrant/.ssh/id_rsa
# chmod 600 /home/vagrant/.ssh/id_rsa
# # cp /home/vagrant/.ssh/id_rsa.pub /vagrant/id_rsa.vagrant.$(hostname).pub
# cp /home/vagrant/.ssh/id_rsa.pub /vagrant/id_rsa.vagrant.$(CLUSTER_NAME).pub
# chown vagrant:vagrant /vagrant/id_rsa.vagrant.$(CLUSTER_NAME).pub
# chmod 600 /vagrant/id_rsa.vagrant.$(CLUSTER_NAME).pub

# cp /home/vagrant/.ssh/id_rsa /vagrant/id_rsa.vagrant.$(CLUSTER_NAME)
# chown vagrant:vagrant /vagrant/id_rsa.vagrant.$(CLUSTER_NAME)
# chmod 600 /vagrant/id_rsa.vagrant.$(CLUSTER_NAME)

# Attente (utile encore ??)
# echo "‚è≥ Attente que l'API Kubernetes soit accessible via la VIP ($CONTROLPLANE_VIP:6443)..."
# start=$(date +%s)
# timeout=120
# until curl -k https://$CONTROLPLANE_VIP:6443/version >/dev/null 2>&1; do
#   echo -n "..."
#   sleep 3
#   now=$(date +%s)
#   if (( now - start > timeout )); then
#     echo ""
#     echo "üö® Timeout atteint. L'API Kubernetes n'est pas accessible via la VIP"
#     exit 1
#   fi
# done

# echo ""
# echo "‚úÖ API Kubernetes accessible via la VIP. Suite du provisioning..."


echo "‚è≥ Attente que l'API Kubernetes soit disponible pour installation du CNI..."
for i in {1..60}; do
  su - vagrant -c "kubectl get nodes &>/dev/null" && break
  sleep 2
done

# Installation du CNI
echo "üîß CNI installation : $CNI_PLUGIN"
if [[ "$CNI_PLUGIN" == "flannel" ]]; then
  su - vagrant -c "kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml"
elif [[ "$CNI_PLUGIN" == "cilium" ]]; then
  if ! command -v helm &> /dev/null; then
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
  fi
  su - vagrant -c "helm repo add cilium https://helm.cilium.io/"
  su - vagrant -c "helm repo update"
  su - vagrant -c "helm install cilium cilium/cilium \
    --namespace kube-system \
    --set kubeProxyReplacement=true \
    --set kubeProxyReplacementStrict=true \
    --set encryption.enabled=true \
    --set encryption.type=wireguard \
    --set enableL7Proxy=true \
    --set k8sServiceHost=$MY_IP \
    --set k8sServicePort=6443 \
    --set operator.replicas=1"
else
  echo "[ERREUR] CNI '$CNI_PLUGIN' inconnu."
  exit 1
fi


# G√©n√©ration du script de jointure pour workers
# JOIN_COMMAND=$(kubeadm token create --print-join-command)
# OLD_IP=$(echo "$JOIN_COMMAND" | awk '{print $3}' | cut -d: -f1)
# JOIN_COMMAND=$(echo "$JOIN_COMMAND" | sed "s/$OLD_IP/$MY_IP/")
# echo "$JOIN_COMMAND" > /vagrant/join-${CLUSTER_NAME}.sh
# chown vagrant:vagrant /vagrant/join-${CLUSTER_NAME}.sh
# chmod +x /vagrant/join-${CLUSTER_NAME}.sh

# Removing taint node-role.kubernetes.io/control-plane:NoSchedule
echo "üîß  Removing Taint node-role.kubernetes.io/control-plane:NoSchedule"
NODE_NAME=$(hostname)
su - vagrant -c "kubectl taint node \"$NODE_NAME\" node-role.kubernetes.io/control-plane-"

#############  POUR DEBUG ##############
# cat <<EOF > /etc/env-k8s-vars
# export CONTROLPLANE_VIP=CONTROLPLANE_VIP
# export MY_IP=$MY_IP
# export K8S_VERSION=K8S_VERSION
# export POD_CIDR=POD_CIDR
# export BASE_IP=BASE_IP
# export START_OCTET=START_OCTET
# export NUM_CONTROLPLANE=NUM_CONTROLPLANE
# export CONTAINER_RUNTIME=CONTAINER_RUNTIME
# export TOKEN=$TOKEN
# export HASH=$HASH
# export CERT_KEY=$CERT_KEY
# export JOIN_COMMAND_CONTROLPLANE=$JOIN_COMMAND_CONTROLPLANE
# export JOIN_COMMAND=$JOIN_COMMAND

# EOF
########################################

echo "üèÅ Primary CONTROLPLANE node $(hostname) successfully joined the Kubernetes cluster !"